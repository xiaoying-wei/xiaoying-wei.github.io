<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">

<html class="gr__pi_cs_tsinghua_edu_cn"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<title>Xiaoying Wei</title>
		<meta name="description" content="Ph.D student">
		<meta http-equiv="pragma" content="no-cache">
		<meta http-equiv="author" content="xiaoyingwei">
		<link rel="stylesheet" href="./wxy/plain.css" type="text/css">
		<link href="./wxy/font-awesome.min.css" rel="stylesheet">
	    <link rel="stylesheet" href="./wxy/academicons.css">
		
		<style type="text/css">
			div.main {
				width: 1130px;
				margin: auto auto;
				overflow: auto}
			div.introduction {
				float: left;
				width: auto;
				margin: 0px;
				padding: 00px;}
			div.labimgdiv {
				float: right;}
			td.name {
				font-family: Arial, Verdana, sans-serif;
				font-size: 42px;}
			span.Chinese {
				font-family: Trebuchet MS, KaiTi, BiauKai, sans-serif;
				font-size: 42px;}
			td.email {
				font-family: Arial, Verdana, sans-serif;
				text-decoration:none;
				font-size: 23px;
				color: #222222;}
			img.labimg {
				width: 420px;
				height: 80px;}
			table.intro_table {
				margin-top: -15px;
			}
			div.statement {
				width: 920px;
				font-family: Arial, Verdana, sans-serif;
				margin-left: 0px;
				font-size: 20px;
			}
			img.profile {
				width: 150px;
				margin-top: 5px;
				margin-left: 25px;
			}
			a.link {
				color: #3159D1;
				text-decoration: none;
			}
			h1.heading {
				font-size: 33px;
				font-weight: normal;
				font-family: Trebuchet MS, Helvetica, Arial, Verdana sans-serif;
				margin: 1px;
				margin-bottom: -8px;
			}
			table.pubication {
				height: 240px;
			}
			img.thumbnail {
				width: 280px;
				height: 210px;
				margin-left: 0px;
				margin-top: -17px;
			}
			td.paperintro {
				text-align:left; 
				vertical-align:top;
			}
			p.paperintro {
				margin-left: 3px;
				margin-top: 10px;
				width: 836px;
				line-height:148%
			}
			span.conference {
				font-family: Trebuchet MS, Helvetica, Arial, Verdana sans-serif;
				font-weight:bold;
				font-size:20px;
				color: #8B0000;
			}
			span.papertitle {
				font-family: Helvetica, Arial, Verdana sans-serif;
				font-weight:bold;
				font-size:22px;
			}
			span.papertitlesmall {
				font-family: Arial, Verdana;
				font-weight:bold;
				font-size:21px;
			}
			span.papertitlesmaller {
				font-family: Arial, Verdana;
				font-weight:bold;
				font-size:20px;
			}
			span.authorlist {
				font-family: Trebuchet MS, Helvetica, Arial, Verdana sans-serif;
				font-weight:normal;
				font-size:19px;
				color: #505050;
			}
			span.authorme {
				font-family: Trebuchet MS, Helvetica, Arial, Verdana sans-serif;
				font-size:19px;
				font-weight:bold;
				color: #303030;
			}
			p.abstract {
				margin-left: 3px;
				margin-top: -8px;
				width: 835px;
				font-family:  Arial, Verdana sans-serif;
				font-size:19px;
				color: #505050;
			}
			a.resource {
				font-family: Helvetica, Arial, Verdana sans-serif;
				color: #3159D1;
				text-decoration: none;
			}
			a.resource_empty {
				font-family: Helvetica, Arial, Verdana sans-serif;
				color: #888888;
				text-decoration: none;
			}
			td.experienceuniversity {
				width: 920px;
				font-family: Helvetica, Arial, Verdana sans-serif;
				font-size: 20px;
				font-weight:bold;
			}
			td.positionexperience {
				width: 920px;
				font-family: Trebuchet MS, Helvetica, Arial, Verdana sans-serif;
				font-size: 20px;
				font-style: italic;
			}
			td.otherexperience {
				width: 920px;
				font-family: Helvetica, Arial, Verdana sans-serif;
				font-size: 19px;
			}
			p.experience-explanation {
				margin-top: 3px;
				width: 840px;
				font-family: Helvetica, Arial, Verdana sans-serif;
				font-size: 19px;
				color: #404040;
			}
			td.time {
				width: 200px;
				font-family: Trebuchet MS, Helvetica, Arial, Verdana sans-serif;
				font-size: 20px;
			}
			a.company-link{
				text-decoration: none;
			}
			td.employment {
				width: 920px;
				font-family: Trebuchet MS, Helvetica, Arial, Verdana sans-serif;
				font-size: 20px;
			}
			p.updatetime {
				font-family:  Arial, Verdana sans-serif;
			}
		</style>
	</head>
	<body data-gr-c-s-loaded="true">
		<div class="main">
			<div class="introduction">
				<table class="name_email">
					<tbody><tr>
						<td class="name">Xiaoying Wei</td>
					</tr>
					<tr>
						<td class="email">
							xweias@connect.ust.hk
						</td>
					</tr>
				</tbody></table>
			</div>
			
		</div>
		<div class="main">
			<hr>
			<table class="intro_table">
				<tbody><tr>
					<td>
						<div class="statement">
						<p align="justify">
						I am a Ph.D. student (2022 ~ ) at the Computational Media and Arts (CMA), HKUST, and supervised by Prof. Mingming Fan. My research interest is Human-Computer Interaction (HCI). I received my Master's degree from the Department of CST at Tsinghua University in 2020 and my bachelor's degree from Xiamen University in 2017.
						</p>
						<p align="justify">
						I focus on the fields of HCI, Accessibility, and Virtual Reality. Specifically, I apply user-centered design, VR/AR, sensing, and qualitative research methods to empower people by 1) Supporting Better Interpersonal Communication Using Novel VR/AR Techniques, and 2) Understanding and Mitigating Aging and Accessibility Challenges by Increasing Their Social Connections.
					</p>
						<p align="justify">
						I am glad to cooperate with the researchers in the HCI field.
						</p>
						</div>
					</td>
					<td>
						<img src="./xiaoyingwei.jpeg" class="profile" alt="Xiaoying Wei" title="Xiaoying Wei">
					</td>
				</tr>
			</tbody></table>
		</div>
		<br>
		
		<div class="main">
			<h1 class="heading">Publications</h1>
			<hr>

			<table class="pubication">
				<tbody><tr>
					<td class="thumbnail">
						<img src="./CSCW25-LitReview.png" class="thumbnail">
					</td>
					<td class="paperintro">
						<p class="paperintro">
							<span class="conference">CSCW 2025 (TH-CPL A)</span>
							<br>
							<span class="papertitlesmall">Systematic Literature Review of Using Virtual Reality as a Social Platform in HCI Community</span>
							<br>
							<span class="authorlist"> <span class='authorme'>Xiaoying Wei</span>, Xiaofu Jin, Linge Kan, Yukang Yan, Mingming Fan*</span>
						</p>
						<p class="abstract" align="justify">
							Virtual reality (VR) is increasingly used as a social platform for users to interact and build connections in an immersive virtual environment. We conducted a systematic review of 94 publications in the HCI field to examine how VR is designed and evaluated for social purposes. According to the results, we uncover several research gaps and further propose future directions for designing and developing VR for enhancing social experience... 
							<br>
							
					
						</p>
						<p></p>
					</td>
				</tr>
			</tbody></table>

			<table class="pubication">
				<tbody><tr>
					<td class="thumbnail">
						<img src="./AI-CSCW25.png" class="thumbnail">
					</td>
					<td class="paperintro">
						<p class="paperintro">
							<span class="conference">CSCW 2025 (TH-CPL A)</span>
							<br>
							<span class="papertitlesmall">AI as a Bridge Across Ages: Exploring The Opportunities of Artificial Intelligence in Supporting Inter-Generational Communication in Virtual Reality</span>
							<br>
							<span class="authorlist"> <span class='authorme'>Xiaoying Wei</span>, Zhen Song, Jiawei Li, Emily Kuang, Jie Hao, Dongdong Weng, Mingming Fan*</span>
						</p>
						<p class="abstract" align="justify">
							Inter-generational communication is essential for bridging generational gaps and fostering mutual understanding. We explored the opportunities of AI in supporting inter-generational communication in VR. We developed three technology probes (e.g., Content Generator, Communication Facilitator, and Info Assistant) in VR and employed them in a probe-based participatory design study with twelve inter-generational pairs... 
							<br>
							
					
						</p>
						<p></p>
					</td>
				</tr>
			</tbody></table>

			<table class="pubication">
				<tbody><tr>
					<td class="thumbnail">
						<img src="./CHI24-lightsword.png" class="thumbnail">
					</td>
					<td class="paperintro">
						<p class="paperintro">
							<span class="conference">CHI 2024 (TH-CPL A)</span>
							<br>
							<span class="papertitlesmall">LightSword: A Customized Virtual Reality Exergame for Long-Term Cognitive Inhibition Training in Older Adults</span>
							<br>
							<span class="authorlist"> Qiuxin Du, Zhen Song, Haiyan Jiang, <span class='authorme'>Xiaoying Wei</span>, Dongdong Weng, Mingming Fan*</span>
						</p>
						<p class="abstract" align="justify">
							The decline of cognitive inhibition significantly impacts older adults’ quality of life and well-being. However, existing commercial VR exergames were unsuitable for older adults’ long-term cognitive training. We developed a customized VR cognitive training exergame (LightSword) based on Dual-task and Stroop paradigms for long-term cognitive inhibition training among healthy older adults... 
							<br>
							<a href="./CHI_2024__Cognitive_Training.pdf" target="_blank" class="resource">[PDF]</a>
					
						</p>
						<p></p>
					</td>
				</tr>
			</tbody></table>

			<table class="pubication">
				<tbody><tr>
					<td class="thumbnail">
						<img src="./CHI24-AR-OA-Learning.png" class="thumbnail">
					</td>
					<td class="paperintro">
						<p class="paperintro">
							<span class="conference">CHI 2024 (TH-CPL A)</span>
							<br>
							<span class="papertitlesmall">Exploring the Opportunity of Augmented Reality (AR) in Supporting Older Adults to Explore and Learn Smartphone Applications</span>
							<br>
							<span class="authorlist"> Xiaofu Jin, Wai Tong, <span class='authorme'>Xiaoying Wei</span>, Xian Wang, Emily Kuang, Xiaoyu Mo, Huamin Qu, Mingming Fan*</span>
						</p>
						<p class="abstract" align="justify">
							The global aging trend compels older adults to navigate the evolving digital landscape, presenting a substantial challenge in mastering smartphone applications. While Augmented Reality (AR) holds promise for enhancing learning and user experience, its role in aiding older adults’ smartphone app exploration remains insufficiently explored. Our research highlights AR’s effectiveness in reducing physical and cognitive strain among older adults during app... 
							<br>
							<a href="./CHI24_ARSupportOlderLearn.pdf" target="_blank" class="resource">[PDF]</a>
					
						</p>
						<p></p>
					</td>
				</tr>
			</tbody></table>

			<table class="pubication">
				<tbody><tr>
					<td class="thumbnail">
						<img src="./MM23-Meditation.png" class="thumbnail">
					</td>
					<td class="paperintro">
						<p class="paperintro">
							<span class="conference">MM 2024 (TH-CPL A)</span>
							<br>
							<span class="papertitlesmall">Designing Loving-Kindness Meditation in Virtual Reality for Long-Distance Romantic Relationships</span>
							<br>
							<span class="authorlist"> Xian Wang, Xiaoyu Mo, Lik-Hang Lee, <span class='authorme'>Xiaoying Wei</span>, Xiaofu Jin, Mingming Fan, Pan Hui *</span>
						</p>
						<p class="abstract" align="justify">
							Loving-kindness meditation (LKM) is used in clinical psychology for couples’ relationship therapy, but physical isolation can make the relationship more strained and inaccessible to LKM. This paper organized a series of workshops with couples to build a prototype of a couple-preferred LKM app. We derived design considerations for such VR apps and created a prototype for couples to experience...
							<br>
							<a href="./MM23-Meditation.pdf" target="_blank" class="resource">[PDF]</a>
					
						</p>
						<p></p>
					</td>
				</tr>
			</tbody></table>

			<table class="pubication">
				<tbody><tr>
					<td class="thumbnail">
						<img src="./VRGPGC.png" class="thumbnail">
					</td>
					<td class="paperintro">
						<p class="paperintro">
							<span class="conference">CHI 2023 (TH-CPL A)</span>
							<br>
							<span class="papertitlesmall">Bridging the Generational Gap: Exploring How Virtual Reality Supports Remote Communication Between Grandparents and Grandchildren</span>
							<br>
							<span class="authorlist"> <span class='authorme'>Xiaoying Wei</span>, Yizheng Gu, Emily Kuang, Beiyan Cao, Xian Wang, Xiaofu Jin, Mingming Fan*</span>
						</p>
						<p class="abstract" align="justify">
							When living apart, grandparents and grandchildren often use audio-visual communication approaches to stay connected. However, these approaches seldom provide sufficient companionship due to a lack of co-presence and spatial interaction, which can be fulfilled by immersive virtual reality. To understand how grandparents and grandchildren might leverage VR to facilitate their remote communication and better inform future design, we conducted this work... 
							<br>
							<a href="" target="_blank" class="resource">[PDF]</a>
					
						</p>
						<p></p>
					</td>
				</tr>
			</tbody></table>

			<table class="pubication">
				<tbody><tr>
					<td class="thumbnail">
						<img src="./communicationinVR.png" class="thumbnail">
					</td>
					<td class="paperintro">
						<p class="paperintro">
							<span class="conference">ChineseCHI 2022 Honorable Mention Award</span>
							<br>
							<span class="papertitlesmall">Communication in Immersive Social Virtual Reality: A Systematic Review of 10 Years' Studies</span>
							<br>
							<span class="authorlist"> <span class='authorme'>Xiaoying Wei</span>, Xiaofu Jin, Mingming Fan* </span>
						</p>
						<p class="abstract" align="justify">
							As virtual reality technologies have improved in the past decade, more research has investigated how they could support more effective communication in various contexts to improve collaboration and social connectedness. We conducted a systematic review of the studies investigating communication in social VR in the past ten years by following the PRISMA guidelines.
							<br>
							<a href="./ChineseCHI22.pdf" target="_blank" class="resource">[PDF]</a>
						</p>
						<p></p>
					</td>
				</tr>
			</tbody></table>

			<table class="pubication">
				<tbody><tr>
					<td class="thumbnail">
						<img src="./Synapse.png" class="thumbnail">
					</td>
					<td class="paperintro">
						<p class="paperintro">
							<span class="conference">UbiComp 2022 (TH-CPL A)</span>
							<br>
							<span class="papertitlesmall">Synapse: Interactive Guidance by Demonstration with Trial-and-Error Support for Older Adults to Use Smartphone Apps</span>
							<br>
							<span class="authorlist"> Xiaofu Jin, Xiaozhu Hu, <span class='authorme'>Xiaoying Wei</span>, Mingming Fan*</span>
						</p>
						<p class="abstract" align="justify">
						As smartphones are widely adopted, mobile applications are emerging to provide critical services. This trend may create barriers for older adults. We designed an app-independent mobile service for help-givers to create a multimodal interactive tutorial on a smartphone and for help-receivers (e.g., older adults) to receive interactive guidance with trial-and-error support when they work on the same task...
						<br>
							<a href="./Synapse.pdf" target="_blank" class="resource">[PDF]</a>
							
						</p>
						<p></p>
					</td>
				</tr>
			</tbody></table>

			<table class="pubication">
				<tbody><tr>
					<td class="thumbnail">
						<img src="./AuthTrack.png" class="thumbnail">
					</td>
					<td class="paperintro">
						<p class="paperintro">
							<span class="conference">CHI 2021 (TH-CPL A)</span>
							<br>
							<span class="papertitlesmall">Auth+Track: Enabling Authentication Free Interaction on Smartphone by Continuous User Tracking</span>
							<br>
							<span class="authorlist">Chen Liang, Chun Yu, <span class='authorme'>Xiaoying Wei</span>, Xuhai Xu, Yongquan Hu, Yuntao Wang, Yuanchun Shi</span>
						</p>
						<p class="abstract" align="justify">
						We propose Auth+Track, a novel authentication model that aims to reduce redundant authentication in everyday smartphone usage. By sparse authentication and continuous tracking of the user's status, Auth+Track eliminates the "gap" authentication between fragmented sessions and enables "Authentication Free when User is Around"...
						<br>
							<a href="./AuthTrack.pdf" target="_blank" class="resource">[PDF]</a>
							
						</p>
						<p></p>
					</td>
				</tr>
			</tbody></table>

			<table class="pubication">
				<tbody><tr>
					<td class="thumbnail">
						<img src="./QwertyRing.jpg" class="thumbnail">
					</td>
					<td class="paperintro">
						<p class="paperintro">
							<span class="conference">UbiComp 2021 (TH-CPL A)</span>
							<br>
							<span class="papertitlesmall"> QwertyRing: Text Entry on Physical Surfaces Using a Ring</span>
							<br>
							<span class="authorlist"> Yizheng Gu, Chun Yu, Zhipeng Li, Zhaoheng Li, <span class="authorme">Xiaoying Wei</span>, and Yuanchun Shi</span>
						</p>
						<p class="abstract" align="justify">
						The software keyboard is widely used on digital devices such as smartphones, computers, and tablets. The software keyboard operates via touch, which is efficient, convenient, and familiar to users. However, some emerging technology devices such as AR/VR headsets and smart TVs do not support touch-based text entry. In this paper, we present QwertyRing, a technique that supports text entry on physical surfaces using an IMU ring...
						<br>
							<a href="./QwertyRing.pdf" target="_blank" class="resource">[PDF]</a>
							
							
						</p>
						<p></p>
					</td>
				</tr>
			</tbody></table>

			<table class="pubication">
				<tbody><tr>
					<td class="thumbnail">
						<img src="./handsee.png" class="thumbnail">
					</td>
					<td class="paperintro">
						<p class="paperintro">
							<span class="conference">CHI 2019 (TH-CPL A)</span>
							<br>
							<span class="papertitlesmall">HandSee: Enabling Full Hand Interaction on Smartphones with Front Camera-based Stereo Vision</span>
							<br>
							<span class="authorlist"><small>Yu Chun, <span class="authorme"><small>Xiaoying Wei</small></span>, Shubh Vachher, Yue Qin, Chen Liang, Yueting Weng, Yizheng Gu, Yuanchun Shi</span>
						</p>
						<p class="abstract" align="justify">
						We present HandSee, a novel sensing technique that can capture the state of the user’s hands touching or gripping a smartphone. We place a prism mirror on the front camera to achieve a stereo vision of the scene above the touchscreen surface. HandSee enables a variety of novel interaction techniques and expands the design space for full hand interaction on smartphones...
						<br>
							<a href="./HandSee.pdf" target="_blank" class="resource">[PDF]</a>
							
						</p>
						<p></p>
					</td>
				</tr>
			</tbody></table>




			<table class="pubication">
				<tbody><tr>
					<td class="thumbnail">
						<img src="./TappingRing.png" class="thumbnail">
					</td>
					<td class="paperintro">
						<p class="paperintro">
							<span class="conference">UIST 2019 (TH-CPL A)</span>
							<br>
							<span class="papertitlesmall">Accurate and Low-Latency Sensing of Touch Contact on Any Surface with Finger-Worn IMU Sensor</span>
							<br>
							<span class="authorlist"> Yizheng Gu, Yu Chun, Zhipeng Li, Weiqi Li, Shuchang Xu, <span class="authorme">Xiaoying Wei</span>, Yuanchun Shi</span>
						</p>
						<p class="abstract" align="justify">
						Head-mounted MR systems enable touch interaction on any physical surface. However, optical methods (i.e., with cameras on the headset) have difficulty in determining the touch contact accurately. We show that a finger ring with IMU can substantially improve the accuracy of contact sensing from 84.74% to 98.61% (f1 score), with a low latency of 10 ms...
						<br>
							<a href="./TappingRing.pdf" target="_blank" class="resource">[PDF]</a>
							
						</p>
						<p></p>
					</td>
				</tr>
			</tbody></table>

			<br>
			<br>
		</div>
		
		

		<div class="main">
			<h1 class="heading">Education</h1>
			<hr>
			<table>
				<tbody><tr>
					<td class="experienceuniversity">
						HKUST
					</td>
					<td class="time">
						02/2022 - Present 
					</td>
				</tr>
				<tr>
					<td class="positionexperience">
						Ph.D. student in Computational Media and Arts
					</td>
				</tr>
			</tbody></table>
			<br>
			<table>
				<tbody><tr>
					<td class="experienceuniversity">
						Tsinghua University
					</td>
					<td class="time">
						09/2017 - 06/2020 
					</td>
				</tr>
				<tr>
					<td class="positionexperience">
						M.S. student in Computer Science and Technology
					</td>
				</tr>
			</tbody></table>
			<br>
			<table>
				<tbody><tr>
					<td class="experienceuniversity">
						Xiamen University
					</td>
					<td class="time">
						09/2013 - 06/2017 
					</td>
				</tr>
				<tr>
					<td class="positionexperience">
						B.S. student in Software Institute
					</td>
				</tr>
			</tbody></table>
			<br>
			<br>
		</div>


		<div class="main">
			<h1 class="heading">Internship &amp; Work Experience</h1>
			<hr>

			<table>
				<tbody><tr>
					<td class="employment">
						<b>Product Manager</b>, <i>Meituan</i>
					</td>
					<td class="time">
						06/2020 - 11/2021
					</td>
				</tr>
			</tbody></table>
			
			<table>
				<tbody><tr>
					<td class="employment">
						<b>UX designer</b>, <i>Huawei</i>
					</td>
					<td class="time">
						06/2018 - 09/2018
					</td>
				</tr>
			</tbody></table>

			<br>
			<br>
		</div>	
		
		<div class="main">
			<h1 class="heading">Honors &amp; Awards</h1>
			<hr>
			<table>
				<tbody><tr>
					<td class="employment">
						Outstanding award of Tsinghua University Challenge Cup
					</td>
					<td class="time">
						&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;&nbsp;&nbsp;2018
					</td>
				</tr>
				<tr>
					<td class="employment">
						Second prize of Service Outsourcing Enterpreneurship Competition for Chinese College Student 
					</td>
					<td class="time">
						&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;&nbsp;&nbsp;2016
					</td>
				</tr>
				<tr>
					<td class="employment">
						Silver & best Popularity Award of Creative Public Service Advertising Competition in Fujian
					</td>
					<td class="time">
						&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;&nbsp;&nbsp;2016
					</td>
				</tr>
				
			</tbody></table>
			<br>
			<br>
		</div>
		
		<div class="main">
			<h1 class="heading">Skills</h1>
			<hr>
			<table>
				<tbody><tr>
					<td class="employment">
						<i>Using Maya, Flash, AE, Pr, PS, AI for prototyping, 3D modeling and effect display. </i>
					</td>
				</tr>
				<td class="employment">
						<i>Using Unity3D, Andriod Studio, Processing for DEMO development. </i>
					</td>
			</tbody></table>
			<br>
		</div>
		
		<div class="main">
			<br>
			<br>
			<p class="updatetime">
			Updated in Jan. 2023
			</p>
		</div>	
	
</body></html>
